import streamlit as st
from streamlit_shap import st_shap

import pandas as pd
import numpy as np
import io
import base64
import pickle
import sklearn
from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt
import shap
shap.initjs() # for visualization

########################################################################################################################################################################
# D√©finition du main()
########################################################################################################################################################################

def main():
	st.sidebar.title("RainsBerry")
	#st.set_page_config(
	#page_title="RainsBerry - M√©t√©o",
	#page_icon="üëã",
	#layout="wide",)
	Menu = st.sidebar.radio(
		"Menu",
		('Le Projet M√©t√©o', 'Dataset & PreProcessing','DataViz','Modelisations','Performances','Simulations','Clustering','S√©ries Temporelles','Deep Learning','Conclusion','Rapport'))
	if Menu == 'Le Projet M√©t√©o':
		from PIL import Image
		image = Image.open('images/RainsBerry_2.jpg')
		st.image(image,width=600,caption="")
		'''
		* Le projet pr√©sent√© dans ce streamlit a √©t√© d√©velopp√© dans le cadre de la formation Data Scientist de Datascientest.com - Promotion Octobre 2021.
		* L'objectif premier de ce projet est de mettre en application les diff√©rents acquis de la formation sur la probl√©matique de pr√©vision m√©t√©o et plus pr√©cis√©ment de r√©pondre √† une question essentielle: va-t-il pleuvoir demain?
		'''
		st.image('images/Intro_m√©t√©o.jpg',width=600,caption="")
		'''
		* En dehors d'int√©resser particuli√®rement les fabricants de parapluie, on comprend aussi que cette question est essentielle que ce soit dans le domaine des loisirs (gestion des parcs d'attraction), de l'agriculture, du traffic routier, et bien d'autres sujets.
		* Le lien du repo github est disponible ici: https://github.com/DataScientest-Studio/RainsBerryPy.
		'''
	if Menu == 'Dataset & PreProcessing':
		PreProcessing()
	if Menu == 'DataViz':
		DataViz()
	if Menu == 'Modelisations':
		Modelisations()
	if Menu == 'Performances':
		Performances()
	if Menu == 'Simulations':
		simulation()
	if Menu == 'Clustering':
		clustering()
	if Menu == 'Rapport':
		rapport()
	st.sidebar.text("")
	st.sidebar.text("Projet DataScientest")
	st.sidebar.text("Promotion DataScientist Octobre 2021")
	st.sidebar.text("Lionel Bottan")
	st.sidebar.text("Julien Coquard")
	st.sidebar.text("Samuel Gu√©rin")
	st.sidebar.write("[Lien du git](https://github.com/DataScientest-Studio/RainsBerryPy)")

########################################################################################################################################################################
# D√©finition de la partie Preprocessing
########################################################################################################################################################################
    
def PreProcessing():
    
    from PIL import Image
    
    st.header("Dataset & PreProcessing")
    '''
    ###Dataset
    '''
    st.subheader("Fichier source")
    image = Image.open('images/weatherAUS.jfif')
    st.image(image, caption='Relev√© M√©t√©o en Australie')
    df=pd.read_csv('data/weatherAUS.csv') #Read our data dataset
    buffer = io.StringIO()
    df.info(buf=buffer)
    s = buffer.getvalue()
    st.write("Pr√©sentation du jeu de donn√©es : ") 
    st.text(s)
    
    st.subheader("Ajout de nouvelles donn√©es") 
    
    st.write("Principaux climats australiens") 
    image = Image.open('images/grd_climats.png')
    st.image(image, caption='Climats australiens')
   	
    st.write("Classification de K√∂ppen") 
    image = Image.open('images/clim_koppen.png')
    st.image(image, caption='Climats - Classification de Koppen')
	
    df=pd.read_csv('data/climatsAUS_v2.csv') #Read our data dataset
    buffer = io.StringIO()
    df.info(buf=buffer)
    s = buffer.getvalue()
    st.write("Pr√©sentation du jeu de donn√©es : ") 
    st.text(s)
    
    st.write("Coordonn√©es GPS")     
    image = Image.open('images/GPS.jfif')
    st.image(image, caption='Coordonn√©es GPS')
    df=pd.read_csv('data/aus_town_gps.csv') #Read our data dataset
    buffer = io.StringIO()
    df.info(buf=buffer)
    s = buffer.getvalue()
    st.write("Pr√©sentation du jeu de donn√©es : ") 
    st.text(s)
    
    '''
    ###Preprocessing
    '''
	


########################################################################################################################################################################
# D√©finition de la partie DataViz
########################################################################################################################################################################
 
def DataViz():
    st.header("DataViz")
    if st.checkbox("Corr√©lations de la pluie du lendemain (RainTomorrow) et de  l'ensoleillement (Sunshine)"):
        st.image('images/Dataviz_corr.jpg')
        '''
        #### Observations :
        * L‚Äôanalyse des corr√©lations nous montre que les liaisons entre les diff√©rents crit√®res sont nombreuses.
        * Quelles sont les variables les plus corr√©l√©es √† RainTomorrow ?
            * Ensoleillement : Sunshine
            * Humidit√© : 3pm et 9am
            * Couverture nuageuse : 3pm et 9am
            * Pluie du jour : RainToday
            * Pression atmosph√©rique : Pressure3pm et Pressure9am
        * L'ensoleillement (Sunshine) est corr√©l√© √† RainTomorow_num malgr√© presque 50% de valeurs manquantes pour cette variable. Quand on regarde les corr√©lations, on peut imaginer de traiter ces valeurs manquantes en r√©gressant Sunshine sur les crit√®res les plus corr√©l√©s, √† savoir :
            * Couverture nuageuse : 3pm et 9am
            * Humidit√© : 3pm et 9am
            * Temp√©rature : Temp3pm, MaxTemp, Temp9am
        '''       
    if st.checkbox("Cartographie"):
        st.image('images/Dataviz_carto.jpg')
        '''
        #### Observations : 
        * Les stations m√©t√©o d'Australie sont regroup√©es en 4 climats diff√©rents :
            * m√©diterrann√©en : stations du sud-ouest et du sud-centre
            * chaud_humide (tropical et subtropical humide) => c√¥te est du pays
            * temp√©r√©_froid (temp√©r√© oc√©anique + montagnard) => plut√¥t sud-est
            * sec (chaud et semi-aride, voire aride) => int√©rieur du pays
        * La distribution mensuelle des pr√©cipitations illustre bien les diff√©rences de climat (mousson estivale pour le climat tropical, hivernale pour le climat m√©diterran√©en).
        * Pour les stations au climat sec, on observe 9% de jours de pluie alors que pour les autres on est aux alentours de 22, 23%.
        '''       
    if st.checkbox("Influence sur la pluie du lendemain"):
        st.image('images/Dataviz_influence.jpg')
        '''
        #### Constats :
        * La distribution des variables Sunshine et Humidity3pm est bien diff√©rente selon RainTomorrow.
        * Pour MinTemp, la distribution est relativement similaire.
        * Pour Rainfall et Evaporation, il faut appliquer la fonction log pour neutraliser l'influence des valeurs extr√™mes. On voit aussi l'influence plus importante de Rainfall sur RainTomorrow (distribution diff√©rente).
        '''      
	
########################################################################################################################################################################
# D√©finition de la partie mod√©lisation
########################################################################################################################################################################

def Modelisations():
    st.header("Mod√©lisations")
    
    Menu_mod = st.sidebar.radio(
     "Menu Mod√©lisations",
     ('Equilibrage des classes','Traitement des valeurs manquantes','S√©lection de variables', 'Conclusion'))

    def Equilibrage():
        st.subheader("√âquilibrage des classes")
        st.image('images/model_01_desequilibre.jpg')
        st.markdown("**Performances d'un mod√®le Random Forest sur le jeu de donn√©es complet :**")
        st.image('images/model_02_sans_equ.jpg')
        if st.checkbox("Apr√®s √©quilibrage"):
            st.image('images/model_03_avec_equ.jpg')
	    st.image('images/model_04_PrecRap.jpg')
		
	#if st.checkbox("Pr√©cision et Rappel"):
        if st.checkbox("Modification du seuil de d√©cision"):
            st.image('images/model_05_seuils_proba.jpg')
            st.image('images/model_06_seuilmaxF1.jpg')
        
    def TraitementNA():
        st.subheader("Traitement des valeurs manquantes")
        st.image('images/model_07_proportionsNA.jpg')
        if st.checkbox("Scores"):
            st.markdown("**Scores en fonction du jeu de donn√©es :**")
            st.image('images/model_08_scores_JD.jpg')
        
    def SelectionVar():
        st.subheader("S√©lection de variables")
        st.image('images/model_09_selectKBest.jpg') 
  
    def Conclusion():
        st.subheader("Conclusion")
        
         
    if Menu_mod == 'Equilibrage des classes':
        Equilibrage()
        
    if Menu_mod == 'Traitement des valeurs manquantes':
        TraitementNA()
        
    if Menu_mod == 'S√©lection de variables':
        SelectionVar()
        
    if Menu_mod == 'Conclusion':
        Conclusion()

########################################################################################################################################################################
# D√©finition de la partie perfomance
########################################################################################################################################################################

def Performances():
    st.header("Performances des mod√®les test√©s")
    '''
    #### Les algorithmes suivants ont √©t√© test√©s en prenant en compte les r√©sultats des analyses pr√©c√©dentes :
    * R√©√©quilibrage du jeu de donn√©es avec RandomUnderSampler. 
    * Conservation de toutes les variables pr√©dictives.
    * Choix de l'algorithme sur le dataset sans les NA (donn√©es r√©elles)
    * En revanche, application possible sur les donn√©es interpol√©es ce qui aurait l'int√©r√™t de pouvoir avoir des pr√©dictions sur les observations qui ont des valeurs manquantes (par exemple, les stations  qui ne mesurent pas certains indicateurs). 

    #### Liste des algorithmes test√©s :
    * Arbre de d√©cision
    * Boosting sur arbre de d√©cision (Adaboost classifier)
    * Isolation Forest (d√©tection d‚Äôanomalies) => non pr√©sent√© car vraiment trop d√©grad√©.
    * R√©gression logistique
    * SVM
    * KNN
    * Random Forest
    * Light GBM
    * Bagging Classifier
    * Stacking Classifier (avec les mod√®les pr√©entrain√©s RandomForest, SVM et LogisticRegression)
	
    ##### Optimisation des mod√®les :
    * Une grille de recherche sur les hyperparam√®tres a √©t√© construite pour les mod√®les avec le choix de maximiser le f1 comme m√©trique de performance et 3 folds pour limiter le surapprentissage.

    ##### Choix du mod√®le :
    * Le mod√®le final sera choisi au regard de la courbe de ROC, de l'AUC globale et surtout des m√©triques f1_score, precision, rappel sur la classe √† mod√©liser.

    ##### D√©finitions :
    * La precision correspond au taux de pr√©dictions correctes parmi les pr√©dictions positives. Elle mesure la capacit√© du mod√®le √† ne pas faire d‚Äôerreur lors d‚Äôune pr√©diction positive.
    * Le recall correspond au taux d‚Äôindividus positifs d√©tect√©s par le mod√®le. Il mesure la capacit√© du mod√®le √† d√©tecter l‚Äôensemble des individus positifs.
    * Le F1-score √©value la capacit√© d‚Äôun mod√®le de classification √† pr√©dire efficacement les individus positifs, en faisant un compromis entre la precision et le recall (moyenne harmonique).
    ''' 
    if st.checkbox("Courbe de ROC"):
        st.image('images/Perf_ROC.jpg')       
    if st.checkbox("Selon le seuil de d√©tection"):
        st.image('images/Perf_seuils.jpg')
        st.image('images/Perf_seuils1.jpg')          
    if st.checkbox("Conclusion"):
        '''
        * La comparaison des algorithmes sur la courbe de ROC nous donne une liste de quatre algorithmes sensiblement plus performants que les autres :
            * la Random Forest
            * le Bagging
            * la XGBoost
            * la Light GBM
        
        * Les comparaisons sur le F1_score en choisissant diff√©rents seuils de probabilit√©s (0.50, F1_max, recall=precision) vont nous conduite √† pr√©f√©rer la XGBOOST qui est l√©g√®rement plus performante que la lightGBM sur le seuil "recall=precision".
        '''
        st.image('images/Perf_conclusion1.jpg')

########################################################################################################################################################################
# D√©finition de la partie simulation
########################################################################################################################################################################

def simulation():
    #Chargement du modele
    picklefile = open("modeles/xgboost.pkl", "rb")
    modele = pickle.load(picklefile)  

    #Definition des features
    features = ["RainToday_Num","Rain_J-1","Rain_J-2","MinTemp","MaxTemp","Sunshine","Evaporation",
        "Humidity3pm","Humidity9am","Pressure9am","Pressure3pm","Cloud3pm","Cloud9am", 
        "Wind9am_cos","Wind3pm_cos","WindGust_cos","Wind9am_sin","Wind3pm_sin","WindGust_sin", 
        "Mois","Clim_type_det"]
                
    st.markdown("# Simulation")

    st.subheader("Lecture des donn√©es")

    Data = st.selectbox("DataFrame: " , ["echantillon","Sydney","AliceSprings","Darwin","Perth","Hobart"])

    if ( Data == "echantillon"):
        df=pd.read_csv('data/echantillon.csv') #Read our data dataset
    if ( Data == "Sydney"):
        df=pd.read_csv('data/Sydney.csv') #Read our data dataset
    if ( Data == "AliceSprings"):
        df=pd.read_csv('data/AliceSprings.csv') #Read our data dataset
    if ( Data == "Darwin"):
        df=pd.read_csv('data/Darwin.csv') #Read our data dataset
    if ( Data == "Perth"):
        df=pd.read_csv('data/Perth.csv') #Read our data dataset
    if ( Data == "Hobart"):
        df=pd.read_csv('data/Hobart.csv') #Read our data dataset    

    st.write("Nombre de lignes : ", df.shape[0]) 
    st.write("Nombre de colonnes : ", df.shape[1]) 

    st.subheader("DataViz")

    DataViz = st.selectbox("Quelle Dataviz ? : " , ["Part jours de Pluie","Correlation","Analyse mensuelle","Impact de RainTomorrow"])

    if ( DataViz == "Part jours de Pluie"):
        #Part des jours de pluie
        fig = plt.figure(figsize=(3,3))
        x = df.RainTomorrow_Num.value_counts(normalize=True)
        colors = sns.color_palette('pastel')[0:5]
        labels = ['Pas de pluie', 'Pluie']
        plt.pie(x, labels = labels, colors = colors, autopct='%.0f%%')
        plt.title("Part des jours de pluie")
        st.write(fig)

    if ( DataViz == "Correlation"):
        fig, ax = plt.subplots(figsize=(15,6))
        ListeCrit = ["RainTomorrow_Num","MinTemp","MaxTemp","Sunshine","Evaporation","Humidity3pm"]
        sns.heatmap(df[ListeCrit].corr(), cmap="YlGnBu",annot=True,ax=ax)
        st.write(fig)

        fig = plt.figure( figsize= (20, 7) )
        ax1 = fig.add_subplot(121)
        ax2 = fig.add_subplot(122)
        corr = df.corr()
        ax1.title.set_text('Correlations de RainTomorrow')
        temp = corr[["RainTomorrow_Num"]].loc[abs(corr["RainTomorrow_Num"]) > 0.2].sort_values(by="RainTomorrow_Num",ascending=False)
        sns.heatmap(temp, cmap="YlGnBu",annot=True,ax=ax1)
        ax2.title.set_text('Correlations de Sunshine')
        temp = corr[["Sunshine"]].loc[abs(corr["Sunshine"]) > 0.2].sort_values(by="Sunshine",ascending=False)
        sns.heatmap(temp , cmap="YlGnBu",annot=True,ax=ax2)
        st.write(fig)


    if ( DataViz == "Analyse mensuelle"):
        fig, ax = plt.subplots(figsize=(15,6))
        ax.title.set_text("Distribution mensuelle des pluies")
        sns.lineplot(ax=ax,data=df, x="Mois", y="Rainfall")
        st.write(fig)

    if ( DataViz == "Impact de RainTomorrow"):
        fig, ax = plt.subplots(figsize=(20,4))
        plt.subplot(131)
        sns.histplot(data=df, x="Sunshine",hue="RainTomorrow_Num",bins=20, multiple="layer", thresh=None)
        plt.subplot(132)
        sns.histplot(data=df, x="MinTemp",hue="RainTomorrow_Num",bins=20, thresh=None)
        plt.subplot(133)
        sns.histplot(data=df, x="Humidity3pm",hue="RainTomorrow_Num",bins=20)
        st.write(fig)

    st.subheader("Pr√©diction")

    if st.button("Predict"):  
        #Courbe de ROC
        probs = modele.predict_proba(df[features])
        y_test =  df["RainTomorrow_Num"]
        fpr, tpr, seuils = sklearn.metrics.roc_curve(y_test, probs[:,1], pos_label=1)
        roc_auc = sklearn.metrics.auc(fpr, tpr)
        fig = plt.figure(figsize=(15,6))
        plt.plot(fpr, tpr, color='purple',  linestyle='--', lw=1, label='Model (auc = %0.3f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle=':', label='Al√©atoire (auc = 0.5)')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Taux faux positifs')
        plt.ylabel('Taux vrais positifs')
        plt.title('Courbe ROC')
        plt.legend(loc="lower right");
        st.pyplot(fig)
    
        #Graphe selon le seuil 
        precision, recall, thresholds = precision_recall_curve(y_test, probs[:, 1], pos_label=1)
        dfpr = pd.DataFrame(dict(precision=precision, recall=recall, threshold=[0] + list(thresholds)))
        dfpr['F1']= 2 * (dfpr.precision * dfpr.recall) / (dfpr.precision + dfpr.recall)
        dfrpr_maxF1 = dfpr[dfpr.F1 == dfpr.F1.max()].reset_index()
        Seuil = dfrpr_maxF1["threshold"].values[0]
        dfpr["Diff_Recall_Precision"] = np.abs(dfpr["recall"]-dfpr["precision"])
        dfrpr_MinDiff = dfpr[dfpr.Diff_Recall_Precision == dfpr.Diff_Recall_Precision.min()].reset_index()
        Seuil1 = dfrpr_MinDiff["threshold"].values[0]
    
        fig = plt.figure(figsize=(15,6))
        plt.plot(dfpr["threshold"], dfpr['precision'],label="precision")
        plt.plot(dfpr["threshold"], dfpr['recall'],label="recall")
        plt.plot(dfpr["threshold"], dfpr['F1'],label="F1")
        plt.axvline(x=0.50,color="gray",label="seuil √† 0.50")
        plt.axvline(x=Seuil,color="red",label="seuil maximisant F1")
        plt.axvline(x=Seuil1,color="purple",label="seuil Recall=Precision")
        plt.title("Choix du seuil sur la classe √† mod√©liser")
        plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')
        st.pyplot(fig)
        #Matrice de confusion
        y_pred = np.where(probs[:,1] >= 0.50, 1, 0)    
        y_pred_best = np.where( probs[:,1] >= Seuil, 1, 0)
        y_pred_best1 = np.where( probs[:,1] >= Seuil1, 1, 0)
        st.text('Matrice de confusion seuil 0.50 :\n ' + classification_report(y_test, y_pred))
        st.text('Matrice de confusion seuil maximisant F1 :\n ' + classification_report(y_test, y_pred_best))
        st.text('Matrice de confusion seuil Recall=Precision :\n ' + classification_report(y_test, y_pred_best1))    
        fig = plt.figure(figsize=(15,6))
        cm = confusion_matrix(y_test, y_pred_best)
        ConfusionMatrixDisplay(cm).plot()
        st.pyplot(fig)
        #Predictions
        prediction = modele.predict(df[features])
        predDf = pd.DataFrame(prediction,columns=["prediction"])
        Sortie = pd.concat([df[["Date","Location","Climat_Koppen","Clim_type_det","RainTomorrow_Num"]],predDf],axis=1)
        #st.write(Sortie)

    #st.subheader("Interpr√©tabilit√©")
    
    #if st.button("Importance des features"):
    #    picklefile = open("modeles/xgboost.pkl", "rb")
    #    modele = pickle.load(picklefile)  
    #    explainer = shap.TreeExplainer(modele)
    #    shap_values = explainer.shap_values(df[features])
    #    st_shap(shap.summary_plot(shap_values, df[features]),height=300)

########################################################################################################################################################################
# D√©finition de la partie rapport
########################################################################################################################################################################
    
def rapport():
    st.write("[Lien git_hut :](https://github.com/DataScientest-Studio/RainsBerryPy)")
    def show_pdf(file_path):
        with open(file_path,"rb") as f:
            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
        pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="800" height="800" type="application/pdf"></iframe>'
        st.markdown(pdf_display, unsafe_allow_html=True)

    show_pdf('https://github.com/SamuelGuerin-Git/RainsBerryPy_save/blob/cac5fac60f5e539aec938a343b8152b3587f9ba4/RainsberryPy%20Meteo%20-%20Rapport%20final.pdf')

########################################################################################################################################################################
# D√©finition de la partie clustering
########################################################################################################################################################################
    
def clustering():
 
    Menu_mod = st.sidebar.radio(
     "Menu Clustering",
     ('Introduction et strat√©gie','1√®re √©tape: Type de climat','2√®me √©tape: R√©gime pluviom√©trique','3√®me √©tape: Variation de temp√©rature', 'Conclusion'))  
    
    def Intro():
        st.subheader("Introduction")
        st.image('images/clustering-in-machine-learning.jpg')

        ''' 
        #### La classification de K√∂ppen est une classification des climats fond√©e sur les pr√©cipitations et les temp√©ratures. Un climat, selon cette classification, est rep√©r√© par un code de deux ou trois lettres :
        * 1√®re lettre : type de climat 
        * 2√®me lettre : r√©gime pluviom√©trique 
        * 3√®me lettre : variations de temp√©ratures.
        #### La combinaison de ces sous-classifications donne la classification de climat de K√∂ppen suivante :
        '''        
        
        st.image('images/Climat de Koppen.jpg',caption='Classification de Koppen')
        ''' 
        ##### Strat√©gie Adopt√©e :
        * 1√®re lettre : type de climat => Algorithme KMeans
        * 2√®me lettre : r√©gime pluviom√©trique => TimeSeriesKmeans Clustering
        * 3√®me lettre : variations de temp√©ratures => TimeSeriesKmeans Clustering
        '''                
        
        
    def KMeans():
        st.subheader("Clustering: Type de climat => KMeans")
        '''
        ### Preprocessing:
        #### Cr√©ation d'un dataframe avec :
        * une ligne par ville
        * pour chaque variable consid√©r√©e, cr√©ation d'un jeu de douze colonnes avec le calcul de la moyenne mensuelle: 
            * 'MinTemp','MaxTemp','Temp9am','Temp3pm',
            * 'Rainfall',
            * 'Evaporation',
            * 'Sunshine',
            * 'WindGustSpeed','WindSpeed9am','WindSpeed3pm',
            * 'Humidity9am','Humidity3pm',
            * 'Pressure9am','Pressure3pm',
            * 'Cloud9am','Cloud3pm',
            * 'RainToday_Num'
        ### Utilisation de l'algorithme KMeans:
        #### M√©thode du coude pour d√©finir le nombre de clusters
        '''
        st.image('images/1L_Coude.jpg')
        '''
        #### Nous consid√©rons 10 clusters.
        
        ### Comparaison Classification de Koppen vs Clustering 
        '''
        st.image('images/1L_ResultatsTab.jpg')
        '''
        ### Comparaison localis√©e
        '''
        st.image('images/1L_ResultatsMap.jpg')
        '''
        #### => Climats extr√™mes bien identifi√©s mais r√©sultats moins convaincants pour les autres. 
        '''
    def TSClustering2L():
        st.subheader("Clustering: R√©gime pluviom√©trique => TimeSeriesKmeans")
        '''
        ### Preprocessing
        ##### S√©lection d'une plage de 3 ans et demi de donn√©es √† partir de janvier 2014 - Plus grand plages avec des relev√©s cons√©cutifs (donn√©es d'origine avec traitement KNN imputer).

        #### R√©sultats du Clustering de S√©ries Temporelles:
        '''
        st.image('images/2L_ResultatsPlot.jpg')
        '''
        ### Comparaison Classification de Koppen vs Clustering
        '''
        st.image('images/21L_ResultatsTab.jpg')
        '''
        ### Comparaison Localis√©e
        '''        
        st.image('images/2L_ResultatsMap.jpg')
        '''
        ##### => Le r√©gime de mousson est bien isol√© et le r√©gime f associ√© au climat humide se retrouve seul dans de nombreux clusters (hormis 1).
        '''
        
    def TSClustering3L():
        st.subheader("Clustering: Variation de temp√©rature")
        '''
        ### Preprocessing
        ##### Similaire √† la classification pr√©c√©dente

        #### R√©sultats du Clustering de S√©ries Temporelles:
        '''
        st.image('images/3L_ResultatsPlot.jpg')
        '''
        ### Comparaison Classification de Koppen vs Clustering
        '''
        st.image('images/3L_ResultatsTab.jpg')
        '''
        ### Comparaison Localis√©e
        '''
        st.image('images/3L_ResultatsMap.jpg')
        '''
        ##### => L‚Äôensemble des classifications des variations de temp√©rature est dans l‚Äôensemble bien ex√©cut√©.
        '''
    def Conclusion(): 
        st.subheader("Conclusion")
        '''
        ### Combinaison des diff√©rents clusters:
        '''
        st.image('images/Clust_ResultatsTab.jpg')
        '''
        #### 32 clusters diff√©rents identifi√©s
        '''
        st.image('images/FinalClust_ResultatsTab.jpg')
        '''
        #### Apr√®s regroupement des clusters identifi√©s sous la m√™me classification de Koppen:
        '''
        st.image('images/Final_ResultatsMap.jpg')
        
    if Menu_mod == 'Introduction et strat√©gie':
        Intro()
        
    if Menu_mod == '1√®re √©tape: Type de climat':
        KMeans()
        
    if Menu_mod == '2√®me √©tape: R√©gime pluviom√©trique':
        TSClustering2L()
        
    if Menu_mod == '3√®me √©tape: Variation de temp√©rature':
        TSClustering3L()
        
    if Menu_mod == 'Conclusion':
        Conclusion()
        
if __name__ == "__main__":
    main()
